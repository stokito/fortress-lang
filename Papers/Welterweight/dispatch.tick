\newcommand{\LDOTS}{\mathinner{\ldotp\hskip-0.4ex\ldotp\hskip-0.4ex\ldotp}}

\section{Overloading and inference implementation strategy}

The entrypoints of an overloaded function can be statically ordered by specificity.
By testing for applicability in most-to-least specific order, dynamic dispatch can be reduced to testing a can-apply predicate for each entrypoint until a match is found.
This reduces overloading resolution to the simpler problem of determining if a entrypoint can be applied to the actual parameters supplied.

This same implementation strategy can also be used whenever there is an order among an overloaded function's entrypoints (for example, a user-specified preference for dispatch, or always using the most-recently-written applicable entrypoint).
When the order depends on the same types used to test applicability there may be more efficient ways to perform the dispatch (for example, binary search if the types happen to be totally ordered -- non-applicability of a mid-point entrypoint implies non-applicability of all more-specific entrypoints), but that is a problem for later.

One goal for an implementation of overloading dispatch is to keep simple cases cheap.

\subsection{Dispatch semi-predicate}

The dispatch semi-predicate for a entrypoint of an overloaded function takes a sequence of ilks as input, and either returns false (fails) if the entrypoint is not applicable, or returns true if the entrypoint is applicable, and in that case, also provides type bindings for any static type parameters present in the entrypoint's signature.  The ilks are type constant expressions; they contain no type variables, but may contain tuples, arrows, instantiated-with-constants generic types, unions, Any, trait, and object types.  Type signatures are composed of type variables, tuples, arrows, instantiated-with-signatures generic types, and type constants.  In particular, a type signature may contain a union type appearing as a type constant, but in that case the elements of the union type cannot contain type variables.  All types are also expressed in their canonical form, so it is known that if $A$ and $B$ are both terms of a union type, then neither is a subtype of the other.

The simplest version of this algorithm supports covariant and invariant generics, but not contravariant generics or domain-contravariant arrows.  Union types are handled, but intersection types are not.  In the absence of contravariance, the semipredicate is organized into two phases:
\begin{enumerate}
\item match type parameters and contexts.  For each static parameter occurrence in the entrypoint's signature, note the ilk and variance of the occurrence.  The variance will be statically determined and can be compiled into the generated code; the ilk must be determined at runtime.
\item propagate lower limits through type constraints, ordered from most-below (given the allowed constraints, most constrained) to least-below.  The goal of overloaded function dispatch is to discover the most specific applicable entrypoint, so inference also aims to obtain the most specific instantiation of an applicable entrypoint.
\end{enumerate}

\subsection{Match type parameters and contexts}
The \textsc{match} function here is presented here as if it were called as a subroutine of the dispatch predicate.  However, most of the code is conditional on the structure of the signature type of the entrypoint, and can be rendered in an open-coded form by a compiler, including only those cases required by a particular entrypoint's signature.

\textsc{Match} takes three parameters.
The first is a type signature that may contain unbound static parameters,
the second is the variance (encoded as +1, 0, and -1, where positive is covariant, 0 is invariant, and negative is contravariant),
and the third is an actual type to be related to the signature, subject to the specified variance.
If covariant, then $\textrm{actual} <: \textrm{signature}$, in the way that values normally match their static types.
Invariance requires equality, and contravariance requires $\textrm{signature} <: \textrm{actual}$.
\textsc{Match} also relies on the set $S$ of type names being inferred, and for each type name $t \in S$ augments upper and lower bound constraint sets $U_t$ and $L_t$.  If the type and signature can be related, then \textsc{match} returns normally and adds necessary constraints to the upper and lower bound sets, which are the input to the constraint propagation step.
If the type and signature cannot be related, then \textsc{match} fails.

As an example, the dispatch predicate for the entry point
\[f\OBR{X,Y,Z}(a:A\OBR{X}, b:B\OBR{X,Y}, c:C\OBR{Y,Z})\]
begins by establishing
$S = \{X,Y,Z\}$,
allocating empty $L_X$, $L_Y$, $L_Z$, $U_X$, $U_Y$, $U_Z$,
and invoking
\[\textsc{Match}(````(A\OBR{X},B\OBR{X,Y},C\OBR{Y,Z})'',+1,\textit{arg\_type})\]

\begin{algorithmic}[1]
\Function{match}{$T$:Type, $V$:Variance, $A$:Type}
  \State \Comment{$T$ is signature type, $A$ is actual}
  \If{$T$ contains no names from $S$}  
     \If{$V \geq 0$}\Comment{co/invariant, require $A <: T$}
        \State verify that $A$ subtypes $T$ \EndIf
     \If{$V \leq 0$}\Comment{contra/invariant, require $T <: A$}
     \State  verify that $T$ subtypes $A$ \EndIf
  \ElsIf{$T$ is a type name $t \in S$}
     \If{$V = +1$}\Comment{covariant, require $A <: T$}
       \State insert $A$ into $L_t$ 
      \ElsIf{$V = 0$}\Comment{invariant, require $T = A$}
       \State insert $A$ into $L_t$
       \State insert $A$ into $U_t$
     \EndIf
  \ElsIf{$T$ is an Arrow $T_{\SSmbox{domain}} \rightarrow T_{\SSmbox{range}}$} 
         \If{$A$ is an Arrow $A_{\SSmbox{domain}} \rightarrow A_{\SSmbox{range}}$}  
           \State \Call{match}{$T_{\SSmbox{domain}}$, 0, $A_{\SSmbox{domain}}$}
           \State \Call{match}{$T_{\SSmbox{range}}$, V, $A_{\SSmbox{range}}$}
         \Else \ dispatch fails
         \EndIf
  \ElsIf{$T$ is a Tuple $(T_1, \LDOTS, T_m)$} 
         \If{$A$ is a Tuple $(A_1, \LDOTS, A_m)$}
           \For{$1 \leq j \leq m$}
             \State \Call{match}{$T_j, V, A_j$}
           \EndFor
         \Else \ dispatch fails
         \EndIf
  \ElsIf{$A$ is a union of types $A_1, \LDOTS, A_m$}
     \State\Comment{$T$ is a generic type expression}
     \If{$V=0$} \ dispatch fails
     \Else
        \For{$1 \leq j \leq m$}\label{UnionSubtypesGeneric}
           \State \Call{match}{$T, V, A_j$}
        \EndFor
     \EndIf
  \Else\Comment{$T$ is a generic type expression, $A$ is not union}
    \State \textbf{let}  $G$ = the generic stem of $T$.
    \If{$\exists M,  A <: M, \textsc{stem}(M) = G, M \textrm{is minimal}$}
       \If{$V = 0 \wedge A \not= M$} \ dispatch fails
       \EndIf
       \State \textbf{let} $(T_1, \LDOTS, T_m)$ = the type parameters of $T$
       \State \textbf{let} $(V_1, \LDOTS, V_m)$ = variances of $T$'s parameters
       \State \textbf{let} $(A_1, \LDOTS, A_m)$ = actual type parameters of $M$
       \For{$1 \leq j \leq m$}
           \State \Call{match}{$T_j, V \ast V_j, A_j$}
       \EndFor
    \Else \ dispatch fails
    \EndIf
  \EndIf
  \EndFunction
\end{algorithmic}
Correctness: induction on type structure, finiteness of signature and actual types.  Most steps are uncomplicated.

The loop on line \ref{UnionSubtypesGeneric} deals with the case where a union type $A$ must be a subtype of an instantiated generic.  The loop ensures that for each term $A_j$ in the union, there is an assignment of type parameters $\bar{P}_j$ such that $A_j <: G\OBR{\bar{P}_j}$.  This in turn ensures that $A = \bigcup_j A_j <: \bigcup_j G\OBR{\bar{P}_j}$, and accumulates all the upper and lower bound constraints necessary to ensure that all the subtypes are simultaneously true.  If none of the bounded intervals are empty, then any $\bar{P}$ within that set provides that  $A <: G\OBR{\bar{P}}$.

\subsection{Propagate lower limits through type constraints}

The restriction on parameter constraint dependence ensures that a cycle-free order exists, and that the constraints can be topologically sorted according to this dependence order (these are the constraints in the declaration of a particular generic entrypoint).  To propagate limits on type parameters, the type parameters are topologically sorted using their constraint declarations to infer an order; a constraint $T_1 <: T_2$ means that $T_1$ precedes $T_2$ in the sort order.
In Fortress where type parameter scoping is left-to-right and newly declared parameters can only be constrained to subtype already declared parameters, processing type parameters in right-to-left scope order satisifies this restriction.

{\it Careful -- our order, lexical-<:, ensures that beginning at the ````bottom'' is well-founded and cycle-free.  It's not just <:.}

The constraint propagation and checking algorithm uses a type operation ````lsub'', for Least Single Upper Bound.  For a lattice, this is lattice join, implemented in the Fortress type system with a type union operation where necessary to complete the type hierarchy to obtain a (semi)lattice (for tuple types, a union may not be necessary, and a comprises clause declares an implicit join type of all the comprised types).  In programming languages with single inheritance the join of any two types will always be a declared type; in other programming languages that support type multiple inheritance $\textrm{lsub}(T,U)$ may be defined in some other way, for instance as the least supertype dominating $T$ and $U$.  The lsub operation must obey the property that for a covariant generic $G$, $\textrm{lsub}(G\OBR{A}, G\OBR{B}) <: G\OBR{\textrm{lsub}(A,B)}$.
The constraint propagation algorithm merely ensures that whatever the definition of lsub is,
if a consistent set of type assignments can be discovered, the most specific one will be found.
\begin{algorithmic}[1]
\For{$t$ topologically ordered by lexical-$<:$}
  \State $l \gets \textrm{lsub}(L_t)$
  \For{$T_{\SSmbox{rhs}}$ where $t <: T_{\SSmbox{rhs}}$}
     \If{$T_{\SSmbox{rhs}}$ is a type constant}
        \State \label{constant} add $T_{\SSmbox{rhs}}$ to $U_t$
     \ElsIf{$l$ is bottom}
        \State \Comment{No lower bounds, cannot fail}
     \Else \Comment{$T_{\SSmbox{rhs}}$ is parameter, generic, tuple, or arrow}
        \State \label{generic} \Call{match}{$T_{\SSmbox{rhs}}$, +1, $l$}
     \EndIf
  \EndFor
  \For{$u$ in $U_t$}
    \If{$l \not <: u$} \label{bounds}
      \State dispatch fails
    \EndIf
  \EndFor
\EndFor
\end{algorithmic}

Each iteration of the inner loop
begins by establishing the best possible lower bound for $t$.  ````Best'' is the most specific (lowest) single type that is above or equal to all the lower bounds of $t$.  Because the constraints are topologically sorted in reverse order of definition, $t$ will not appear in subsequent constraints and thus its lower bound cannot be further modified.  Line \ref{constant} updates the upper bound of $t$.  Line \ref{generic} invokes {\sc match} to ensure that the lower bound of $t$ is structurally able to be a subtype of $T_{\SSmbox{rhs}}$, and to propagate necessary bounds to other static parameters that have not yet been checked and inferred. 

%\subsection{Self-typed generics}
%{\it Explanation of how this works}
%\begin{algorithmic}
%\Step{\PlaceHolder{Self-type step}}
%\If{$l$ is bottom}
%\State do nothing
%\ElsIf{there are self type constraints $t <: S_i\OBR{t}$}
%\State search for $t'$ above $l$ such that $t' <: S_i\OBR{t'}$ for all $S_i$
%\If {$t'$ exists}
%\State $l \gets t'$
%\Else\ dispatch fails
%\EndIf
%\Else\ do nothing
%\EndIf
%\EndStep
%\end{algorithmic}

\subsection{Run-time type representations and operations}
The run-time metadata for trait and object types must support the following three operations, ideally without too much waste of time or space:
\begin{itemize}
\item does X subtype Y?
\item find minimal instance of G that is an ancestor of T
\item join, meet
\end{itemize}

For each trait or object type $T$, the longest erased path to Any ($\textsc{lepa}(T)$) is calculated.  $\textsc{lepa}(\textit{Any})$ is defined to be zero; if $T$ is the trait Object or an arrow or tuple type, $\textsc{lepa}(T)$ is defined to be 1.  For other traits and objects, $\textsc{lepa}(T)$ is defined to be 1 plus the maximum of $\textsc{lepa}(U)$ where $T <:_{\SSmbox{stem}}\ U$.  $T <:_{\SSmbox{stem}}\ U$ can be defined syntactically from the declaration of $T$ by erasing static parameters from both $T$ and any types it is declared to extend.

For an instantiated generic type $T$, $\textsc{args}(T)$ is the sequence of type arguments instantiating the generic, and $\textsc{variances}(T)$ is the corresponding sequence of variances (the same sequence for all instances of the same generic).  $\textsc{stem}(T)$ is the erased stem of a generic $T$.
For non-generic types, \textsc{args} and \textsc{variances} both return the empty sequence, and \textsc{stem} returns the type itself.  As a convenience, for a tuple type $\textsc{stem}(T)$ is ````Tuple'' and $\textsc{args}(T)$ is the sequence of tuple element types. Similarly, \textsc{stem} of an arrow type is ````Arrow''.

For a given trait or object type $T$, the transitive closure of its supertypes is encoded into an array $\textsc{supers}(T)$ of maps from type stems to types.
$\textsc{supers}(T)_i$ contains the map of supertypes of $T$ whose \textsc{lepa} is $i$; the domain of the map is the stems of the supertypes, and each stem maps to the unerased minimal instance of that generic type in the supertype hierarchy. For non-generic supertypes the stem is the type itself, and the type maps to itself. The \textsc{supers} array for $T$ includes an entry for $T$ itself: $\textsc{supers}(T)_{\textsc{lepa}(T)}(\textsc{stem}(T)) = T$.

The maps themselves may be implemented as a simple list of pairs, sorted lists, ordered binary trees, hashmaps, or color-indexed arrays.

Given this data structure, the minimal instance of a generic $G$ supertyping $T$ is $\textsc{Supers}(T)_{\textsc{LEPA}(G)}(G)$.

A subtype query is slightly more involved.
\begin{algorithmic}[1]
\Function{Subtype}{T, U}
  \State\Comment{Return true if $T$ is a subtype of $U$}
  \If{$T = U \vee U = ````\textit{Any}''$} true
  \ElsIf{$\textsc{stem}(T) = ````\textrm{Tuple}''$}
     \State $\textsc{stem}(U) = ````\textrm{Tuple}'' \;\wedge\NEGQQ\displaystyle\bigwedge_{(V,W) \in \textrm{zip}(\textsc{args}(T), \textsc{args}(U))}\NEGQQ\Call{Subtype}{V,W}$ %AND(Subtype(V,U) | V in Args(T))
  \ElsIf{$\textsc{stem}(T) = ````\textrm{Arrow}''$}    
     \State \parbox{3in}{\begin{multline*}
            \textsc{stem}(U) = ````\textrm{Arrow}'' \,\wedge\, \\
            \Call{Subtype}{\textsc{range}(T), \textsc{range}(U)} \wedge \\
            \Call{Equal}{\textsc{domain}(T), \textsc{domain}(U)}
     \end{multline*}}
     %$\textrm{stem}(U) = ````\textrm{Arrow}'' \,\wedge\, \Call{Subtype}{\textsc{range}(T), \textsc{range}(U)} \wedge \Call{Equal}{\textsc{domain}(T), \textsc{domain}(U)}$
  \ElsIf{$\textsc{stem}(T) = ````\cup''$}
     $\!\!\!\!\!\!\displaystyle\bigwedge_{V \in \textsc{args}(T)}\!\!\!\!\!\!\!\!\Call{Subtype}{V,U}$ %AND(Subtype(V,U) | V in Args(T))
  \ElsIf{$\textsc{stem}(T) = ````\cap''$} 
     $\!\!\!\!\!\!\displaystyle  \bigvee_{V \in \textsc{args}(T)}\!\!\!\!\!\!\!\!\Call{Subtype}{V,U}$ %OR(Subtype(V,U) | V in Args(T))
  \ElsIf{$\textsc{stem}(U) = ````\cup''$} 
     $\!\!\!\!\!\!\displaystyle  \bigvee_{V \in \textsc{args}(U)}\!\!\!\!\!\!\!\!\Call{Subtype}{T,V}$ % res :=  OR( Subtype(T,V) | V in ArgsU )
  \ElsIf{$\textsc{stem}(U) = ````\cap''$} 
     $\!\!\!\!\!\!\displaystyle\bigwedge_{V \in \textsc{args(U)}}\!\!\!\!\!\!\!\!\Call{Subtype}{T,V}$ %res := AND( Subtype(T,V) | V in ArgsU )
  \ElsIf{$\textsc{lepa}(T) < \textsc{lepa}(U)$}  false
  \ElsIf{$\textsc{stem}(U) \not\in\textsc{supers}(T)_{\textsc{lepa}(U)}$} false
  \Else
    \State $\textbf{var}\,\textit{res}:\textrm{Boolean} = \textrm{true}$
    \State $\textit{argsU} = \textsc{args}(U)$
    \State $\textit{candidate} = \textsc{supers}(T)_{\textsc{LEPA}(U)}.\textrm{get}(\textsc{stem}(U))$
    \State $\textit{argsC} = \textsc{args}(\textit{candidate})$
    \State $\textit{vars} = \textsc{variances}(\textit{candidate})$
    \For{$0 \le i \le |\textit{argsC}|$} 
       \State \Comment{Non-generics don't iterate, hence true}
       \State \textbf{case} $\textit{vars}_i$ \textbf{of}
       \Indent
          \State $+1 \implies \textit{res} \gets \textit{res} \wedge \Call{Subtype}{\textit{argsC}_i, \textit{argsU}_i}$
          \State  $0 \implies \textit{res} \gets \textit{res} \wedge \textit{argsC}_i = \textit{argsU}_i$
          \State $-1 \implies \textit{res} \gets \textit{res} \wedge \Call{Subtype}{\textit{argsU}_i, \textit{argsC}_i}$
       \EndIndent
    \EndFor
    \State \textit{res}
  \EndIf
\EndFunction
\end{algorithmic}

\section{Variations}

The algorithm just described works with covariant and invariant generic types, union types, and a set of constraints allowed on generic type parameters.  We might wish to relax some of these restrictions and accept more varied inputs, if possible.

\subsection{Additional constraints}
Odersky has noted that covariant data structures benefit from the ability to express type lower bounds[].
Covariant, widening list-append is one example of an operation that benefits from this.  Without the ability to declare that the parameter $U$ is a supertype of $T$, there is no type-correct way to express this.
{\slantverbatim
\begin{verbatim}
trait List[\ covariant T \]
   append[\ U dominates T \](x:U) : List[\ U \]
end
\end{verbatim}
}
In this use of a lower bound (on $U$), $T$ is effectively a constant because it is a parameter of the enclosing generic trait \textit{List} and not a parameter of the \textit{append} method.  This use of ````dominates'' does not present a problem for the algorithm.

More generally, as long as new static parameter constraints can be described without forward references (for example, if they have left-to-right scoping in the parameter list), the $<:$ relation will be cycle-free.

{\it Careful: what about ````T dominates $G\OBR{U}$''?}

\subsection{Intersection types from typecase}

Intersection types can be inferred in the presence of ````typecase'' in a Fortress program, and it may be possible for them to subsequently appear in values -- for example, in $\textit{List}\OBR{\textit{Serializable} \cap \textit{Cloneable}}$.

In the match algorithm this introduces complications when a generic signature, for example, $G\OBR{T}$, must covariantly match an intersection type $A \cap B$.  That is, $A \cap B <: G\OBR{T}$.  This will be true if either $A <: G\OBR{T}$ or $B <: G\OBR{T}$ (or both).  In principle, constraint checking must be performed for each of these combinations, with the most specific (both) case being preferred.  If neither clause matches, then dispatch will fail; if a single clause matches, then there are no alternatives and no combinatorial explosion.  If both clauses match locally, it may be that only one of the two is compatible with other constraints inferred for this entrypoint, and all the various combinations must be checked separately.

However, the restrictions on how generic types may be extended prohibit mutually exclusive constraints from the two clauses of the intersection.
For typecase, the intersection type results from an actual value $V$ with type $O$ that must satisfy all structural constraints on types.  Suppose that $A$ and $B$ both extend instantiations of $G$, so $O <: A <: G\OBR{T_1}$ and $O <: B <: G\OBR{T_2}$.  If $G$ is invariant, then $T_1$ and $T_2$ must be equal, and therefore the constraints for the two clauses are compatible.  If $G$ is covariant, then $T_1$ and $T_2$ may not be the same.

Because $A <: G\OBR{T_1}$ and $B <: G\OBR{T_2}$, we know that $A \cap B <: G\OBR{T_1} \cap G\OBR{T_2} = G\OBR{T_1 \cap T_2}$.  This allows us to conclude that $T_1 \cap T_2$ is a valid lower bound for $T$.  Because the intersection is more specific than (lower than) both $T_1$ and $T_2$ it also allows all combinations of $T_1$ and $T_2$ without the overhead of testing them separately.

Processing the clauses of an intersection type extending a generic signature does require one modification to the \textsc{match} algorithm; if a clause fails to match, it does not by itself indicate dispatch failure for the current entrypoint.  Furthermore, any partial set of lower and upper bound constraints accumulated during the attempted match of a clause must be discarded. For a successful match, the lower bound sets computed for each of the clauses must all be intersected; effectively, the resulting bound sets are each the intersection of unions, which must then be combined with the existing lower bound sets.  Upper bound sets will be merged to form the union of intersections.

\begin{algorithmic}[1]
\Step{\PlaceHolder{Intersection subtypes generic}}
  \If{$A$ is an intersection of types $A_1, \LDOTS, A_m$}
     \State\Comment{$T$ is a generic type expression}
     \If{$V=0$} \ dispatch fails
     \Else
        \State Save existing upper and lower bound sets
        \State Initialize lower bound values (\textit{LBV}) to top
        \State Initialize upper bound values (\textit{UBV}) to bottom
        \State \textbf{var} $\textit{anymatch} = \textit{false}$
        \For{$1 \leq j \leq m$}\label{IntersectionSubtypesGeneric}
           \State Clear upper and lower bound sets
           \State \textbf{try}
           \Indent
           \State \Call{match}{$T, V, A_j$}
           \For{$t \in S$}
           \State $\textit{LBV}_t \gets \textit{LBV}_t \cap \bigcup{t \in S} L_t$
           \State $\textit{UBV}_t \gets \textit{UBV}_t \cup \bigcap{t \in S} L_t$
           \EndFor
           \State $\textit{anymatch} = \textit{true}$
           \EndIndent
           \State \textbf{catch} dispatch failure
        \EndFor
        \If{$\neg \textit{anymatch}$ } \textbf{throw} dispatch failure
        \EndIf
        \State restore upper and lower bound sets
        \State add non-top LBV to respective lower bound sets
        \State add non-bottom UBV to respective upper bounds sets
     \EndIf
   \EndIf
\EndStep
\end{algorithmic}

\subsection{Contravariance}

Adding contravariance to the type system creates the possibility of a combinatorial blowup in constraint matching when a union type must match a generic signature in a contravariant context.  

Consider this contrived example:
{\slantverbatim
\begin{verbatim}
trait S excludes N ... end // String, Number
trait G[\ contravariant X, covariant Y \]
                     extends Edible ... end
object a extends G[\ S, S \] ... end
object b extends G[\ N, N \] ... end
object Pair[\W\](a:W,b:W) ... end
p = Pair(a, b)
trait Eat[\ contravariant Z extends
                        Pair[\ Edible \] \]
object E[\ Z \](z:Z) extends Eat[\ Z \] 
e = E(p)
F[\T extends Edible\](
     eat:Eat[\ Pair[\ G[\T,T\] \] \] = ...
\end{verbatim}
}
F's actual parameter eat has ilk $E\OBR{\textit{Pair}\OBR{G\OBR{N,N}\cup G\OBR{S,S}}}$,
which matches if there is a binding for $T$ that makes the ilk a subtype of
$\textit{Eat}\OBR{\textit{Pair}\OBR{G\OBR{T,T}}}$.
Contravariance of \textit{Eat} reduces this to
\[\textit{Pair}\OBR{G\OBR{T,T}} <: \textit{Pair}\OBR{G\OBR{N,N}\cup G\OBR{S,S}},\]
then to \[G\OBR{T,T} <: G\OBR{N,N}\cup G\OBR{S,S}.\]
The co- and contra-variance of $G$'s parameters require that
$G\OBR{T,T} <: G\OBR{N,N}$ iff $T=N$,
and that $G\OBR{T,T} <: G\OBR{S,S}$ iff $T=S$.
There is no single value of $T$ that will satisfy both constraints simultaneously.

This example, however, is contrived and somewhat useless, and it may be the case that such combinatorial constraint checking will be rare in actual programs.  It is possible to identify easy cases.  Consider the general problem of matching $G\OBR{\bar{T}}$ to $A \cup B$ in a contravariant context; that is, $G\OBR{\bar{T}} <: A \cup B$, where $A$ and $B$ are trait or object types.  The two subproblems are $G\OBR{\bar{T}} <: A$ and $G\OBR{\bar{T}} <: B$; if either subproblem fails to match, then the result is the match of the other subproblem.  If either subproblem succeeds with an empty set of constraints, then the result is the empty set of constraints.

This leaves the case where both subproblems match, and both produce non-empty sets of constraints.  This results when $G\OBR{\bar{\gamma}}$ is declared to (transitively) extend $H\OBR{\bar{\alpha}}$(=$A$) and $J\OBR{\bar{\beta}}$(=$B$), where some elements of $\bar{\gamma}$ appear in $\bar{\alpha}$ and in $\bar{\beta}$, and for each element of $\bar{\gamma}$ appearing in $\bar{\alpha}$ and/or $\bar{\beta}$, the variance for that element is the same in $\bar{\gamma}$, $\bar{\alpha}$, and $\bar{\beta}$.  This is required by the rules for variance context; X-variant static parameters may only appear in X-variant contexts, including supertypes.  As seen in the example, it is also possible that $H$ and $J$ are the same generic type stem, and they may be $G$.

Suppose $H$ and $J$ are both $G$.
Then the two subproblems are $G\OBR{\bar{T_1}} <: G\OBR{\bar{U}}$ and $G\OBR{\bar{T_2}} <: G\OBR{\bar{V}}$; that is, $\bar{T_1} = \bar{U}$ and $\bar{T_2} = \bar{V}$.  Because $G\OBR{\bar{U}} \cup G\OBR{\bar{V}}$ is assumed to be in canonical form, there is no $\bar{T}$ such that $G\OBR{\bar{T}} = G\OBR{\bar{U}} \cup G\OBR{\bar{V}}$.  This is a hard subcase.

Suppose neither $H$ nor $J$ is $G$.
In that case, $G\OBR{\bar{T_1}} <: H\OBR{\bar{U}}$ and $G\OBR{\bar{T_2}} <: J\OBR{\bar{V}}$.
Because $H$ and $J$ are not $G$, canonical form of the union does not preclude the case that $G\OBR{\bar{T_1}}$ and $G\OBR{\bar{T_2}}$ are related.
When that occurs (for example, if $G\OBR{\bar{T_1}} <: G\OBR{\bar{T_2}}$), then one subproblem subsumes the other, and the solution for the larger problem is the set of constraints from the subsuming subproblem.      

Type inference in contravariant context can also generate intersection types that are not directly derived from values.
Canonicalization reduces malformed intersections to bottom; if $A$ excludes $B$, then $A \cap B$ is canonically bottom.  This avoids the combinatorial blowup in the same way that it is avoided for typecase.

\subsection{No union types}

It is possible to use a type system in which union types do not appear.  Many programming languages pseudo-join two types by choosing their nearest dominator in the type hierarchy instead of forming a union type.  This allows contravariant generic types without the combinatorial cost of a contravariant generic-to-union match.

\section{Canonicalization}

The canonical form of union and intersection types is sorted disjunctive normal form without negation.  Exclusion relationships between types allows easy elimination of intersection terms.  Intersections of two types with same generic stem are first flattened before canonicalization, and reconstituted afterwards.  Arrows and tuples are treated as a special case of generic types with the appropriate variance.
\begin{algorithmic}[1]
\Function{Canonicalize}{T}
   \State \Comment{Args of union and intersection are assumed to be in canonical form.}
   \State $s \gets \textrm{stem}(T)$
   \If{$s \ne \textrm{````$\cup$''} \wedge s \ne \textrm{````$\cap$''}$}
      \State \Return{$T$}
   \Else \Comment{$\cup/\cap\OBR{\textit{arg}_1,\LDOTS,\textit{arg}_i,\LDOTS}$}
     \State \PlaceHolder{Flatten/factor generic-of-$\cup$/$\cap$ variant args}
     \If{$s = \textrm{````$\cup$''}$}
       \State \PlaceHolder{Flatten union args}
     \Else \Comment{````$\cap$''}
       \State \PlaceHolder{Flatten intersection args}
       \State \PlaceHolder{Distribute union args}
     \EndIf
     \State \PlaceHolder{Eliminate redundant terms}
     \State \PlaceHolder{Reconstitute generics of intersections and unions}
     \State \PlaceHolder{Sort terms}
   \EndIf
\EndFunction
\end{algorithmic}

\begin{algorithmic}[1]
\Step{\PlaceHolder{Flatten/factor generic-of-$\cup$/$\cap$ variant args}}{}
\While{any generic of union/intersection variant args exist}
\At{covariant parameters of G}
\State  $G\OBR{\LDOTS, \cap(A,B), \LDOTS} \Rightarrow G\OBR{\LDOTS,A,\LDOTS] \cap G[\LDOTS,B,\LDOTS}$
\End
\At{contravariant parameters of G}
\State  $G\OBR{\LDOTS, \cup(A,B), \LDOTS} \Rightarrow G\OBR{\LDOTS,A,\LDOTS] \cap G[\LDOTS,B,\LDOTS}$
\End
\EndWhile
\EndStep
\end{algorithmic}

\begin{algorithmic}[1]
\Step{\PlaceHolder{Flatten union args}}{}
\State \parbox{3in}{\begin{multline*}
            \textrm{Replace} \cup\OBR{X_1, \LDOTS, X_{iA} \cup X_{iB}, \LDOTS, X_m}\\
		    \textrm{with} \cup\OBR{X_1, \LDOTS, X_{iA}, X_{iB}, \LDOTS, X_m}
            \end{multline*}}
\EndStep
\end{algorithmic}

\begin{algorithmic}[1]
\Step{\PlaceHolder{Flatten intersection args}}{}
\State\ 
\EndStep
\end{algorithmic}


\begin{algorithmic}[1]
\Step{\PlaceHolder{Distribute union args}}{}
\State\ 
\EndStep
\end{algorithmic}

\begin{algorithmic}[1]
\Step{\PlaceHolder{Eliminate redundant terms}}
\State \Comment{Simplifying $\cup(T_1, T_2, \LDOTS, T_i, \LDOTS, T_n)$}
   \For{$1\le i \le n$}
     \If{$T_i = \cap\OBR{X_1, \LDOTS, X_m}$}
       \For{$1 \le j,k \le m, j \not= k$}
         \If{$X_j \;\textrm{excludes}\; X_k$}
           \State{remove $T_i$ from union terms}
           \State{\textbf{next}\ $i$}
         \EndIf
       \EndFor
       
       \For{$1 \le j,k \le m, j \not= k$}
         \If{$X_j <: X_k$}
           \State{remove $X_k$ from intersection terms}
         \EndIf
       \EndFor
     \EndIf
   \EndFor
   \For{$1 \le i,j \le n, i \not= j$}
       \If{$T_j <: T_i$}
         \State remove $T_j$ from union terms
       \EndIf
   \EndFor
\EndStep
\end{algorithmic}

\begin{algorithmic}[1]
\Step{\PlaceHolder{Reconstitute generics of intersections and unions}}
\State \Comment{Simplifying $\cup(T_1, T_2, \LDOTS, T_i, \LDOTS, T_n)$}
   \For{$1\le i \le n$}
      \If{$T_i = \cap\OBR{X_1, \LDOTS, X_m}$}
         \For{$1 \le j < k \le n$}
            \If{$X_j = G\OBR{\alpha} \;\textbf{and}\; X_k = G\OBR{\beta}$}
               \State replace $G\OBR{\alpha}$ and $G\OBR{\beta}$ with $G\OBR{\alpha \bigcirc \beta}$
			    \State $\bigcirc$ is $\cup$ at covariant parameters, otherwise $\cap$
		        \State Resulting parameters are subject to further canonicalization.
                \State Excluding intersections and unequal invariant parameters become bottom.
			 	 \State Generic-of-bottom is also bottom.
            \EndIf
         \EndFor
      \EndIf
  \EndFor
\EndStep
\end{algorithmic}

\begin{algorithmic}[1]
\Step{\PlaceHolder{Sort terms}}
\State\ 
\EndStep
\end{algorithmic}
